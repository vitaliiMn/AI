{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BvOn7agNTWE",
        "outputId": "fe197cb3-7003-470c-d894-78456013d987"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/texts/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJshlgUjMPQ_",
        "outputId": "a96b1d2e-9b2b-4a4e-ceff-8ed2ec0fb12b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Всего символов:  59115\n",
            "Всего слов в словаре:  20988\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, SimpleRNN, GRU\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "books = [path + '6.txt']\n",
        "def text_from_file(filepath):\n",
        "    text = \"\"\n",
        "    with open(filepath, 'rb') as book:\n",
        "        text = book.read().decode(encoding='utf-8')\n",
        "    return text\n",
        "\n",
        "raw_text = ''\n",
        "for book in books:\n",
        "    raw_text += text_from_file(book)\n",
        "\n",
        "\n",
        "vocabulary = sorted(list(set(raw_text.split())))\n",
        "char2idx = {u: i for i, u in enumerate(vocabulary)}\n",
        "idx2char = np.array(vocabulary)\n",
        "text_to_int = np.array([char2idx[c] for c in raw_text.split()])\n",
        "n_chars = len(raw_text.split())\n",
        "n_vocab = len(vocabulary)\n",
        "print('Всего символов: ', n_chars)\n",
        "print('Всего слов в словаре: ', n_vocab)\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(raw_text.split()) // (seq_length+1)\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_to_int)\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "def split_input_target(part):\n",
        "    input_text = part[:-1]\n",
        "    target_text = part[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "batch_size = 32\n",
        "num_epochs = 30\n",
        "data = sequences.map(split_input_target)\n",
        "data = data.shuffle(10000).batch(batch_size, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRao-1tkOxCs",
        "outputId": "bf854fcc-fc25-4fa7-b995-5b790ff084ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (32, None, 256)           5372928   \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (32, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (32, None, 20988)         21512700  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,132,604\n",
            "Trainable params: 32,132,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "18/18 [==============================] - 8s 337ms/step - loss: 9.3774\n",
            "Epoch 2/30\n",
            "18/18 [==============================] - 7s 364ms/step - loss: 8.6891\n",
            "Epoch 3/30\n",
            "18/18 [==============================] - 5s 293ms/step - loss: 8.4418\n",
            "Epoch 4/30\n",
            "18/18 [==============================] - 5s 280ms/step - loss: 8.3691\n",
            "Epoch 5/30\n",
            "18/18 [==============================] - 5s 266ms/step - loss: 8.2899\n",
            "Epoch 6/30\n",
            "18/18 [==============================] - 7s 389ms/step - loss: 8.2044\n",
            "Epoch 7/30\n",
            "18/18 [==============================] - 5s 265ms/step - loss: 8.1062\n",
            "Epoch 8/30\n",
            "18/18 [==============================] - 10s 557ms/step - loss: 8.0241\n",
            "Epoch 9/30\n",
            "18/18 [==============================] - 5s 258ms/step - loss: 7.9470\n",
            "Epoch 10/30\n",
            "18/18 [==============================] - 6s 346ms/step - loss: 7.8657\n",
            "Epoch 11/30\n",
            "18/18 [==============================] - 6s 343ms/step - loss: 7.7709\n",
            "Epoch 12/30\n",
            "18/18 [==============================] - 5s 283ms/step - loss: 7.6688\n",
            "Epoch 13/30\n",
            "18/18 [==============================] - 5s 277ms/step - loss: 7.5566\n",
            "Epoch 14/30\n",
            "18/18 [==============================] - 5s 283ms/step - loss: 7.4474\n",
            "Epoch 15/30\n",
            "18/18 [==============================] - 5s 281ms/step - loss: 7.3358\n",
            "Epoch 16/30\n",
            "18/18 [==============================] - 5s 266ms/step - loss: 7.2218\n",
            "Epoch 17/30\n",
            "18/18 [==============================] - 8s 443ms/step - loss: 7.0945\n",
            "Epoch 18/30\n",
            "18/18 [==============================] - 5s 252ms/step - loss: 6.9758\n",
            "Epoch 19/30\n",
            "18/18 [==============================] - 5s 259ms/step - loss: 6.8454\n",
            "Epoch 20/30\n",
            "18/18 [==============================] - 10s 567ms/step - loss: 6.7133\n",
            "Epoch 21/30\n",
            "18/18 [==============================] - 5s 293ms/step - loss: 6.5875\n",
            "Epoch 22/30\n",
            "18/18 [==============================] - 5s 281ms/step - loss: 6.4469\n",
            "Epoch 23/30\n",
            "18/18 [==============================] - 5s 250ms/step - loss: 6.3002\n",
            "Epoch 24/30\n",
            "18/18 [==============================] - 5s 267ms/step - loss: 6.1566\n",
            "Epoch 25/30\n",
            "18/18 [==============================] - 5s 270ms/step - loss: 6.0005\n",
            "Epoch 26/30\n",
            "18/18 [==============================] - 10s 564ms/step - loss: 5.8458\n",
            "Epoch 27/30\n",
            "18/18 [==============================] - 5s 288ms/step - loss: 5.6944\n",
            "Epoch 28/30\n",
            "18/18 [==============================] - 5s 276ms/step - loss: 5.5398\n",
            "Epoch 29/30\n",
            "18/18 [==============================] - 5s 266ms/step - loss: 5.3789\n",
            "Epoch 30/30\n",
            "18/18 [==============================] - 5s 261ms/step - loss: 5.2191\n"
          ]
        }
      ],
      "source": [
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "lstm_sing = Sequential([\n",
        "    Embedding(n_vocab, 256,\n",
        "              batch_input_shape=[batch_size, None]),\n",
        "    LSTM(1024,\n",
        "         return_sequences=True,\n",
        "         stateful=True,\n",
        "         recurrent_initializer='glorot_uniform'),\n",
        "    Dense(n_vocab)\n",
        "])\n",
        "lstm_sing.summary()\n",
        "lstm_sing.compile(loss=loss, optimizer='adam')\n",
        "lstm_sing_dir = './lstm1_checkpoints'\n",
        "lstm_sing_prefix = os.path.join(lstm_sing_dir, \"checkpoint_{epoch}\")\n",
        "lstm_sing_checkpoint = ModelCheckpoint(filepath=lstm_sing_prefix, save_weights_only=True)\n",
        "lstm_one = lstm_sing.fit(data, epochs=num_epochs,callbacks=[lstm_sing_checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vxQG0SSoQScj"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_string, num_generate, temperature=1):\n",
        "    input_eval = np.array([char2idx[s] for s in start_string.split()])\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    text_generated = []\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "    return start_string + ' '.join(text_generated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "cmB5N1t0TICw",
        "outputId": "8874537b-3fdd-43d2-9613-a1c47661bd23"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'почти никакойсписаны процессы сатира нестабильности единству по мной для рассматривать и по тебя, Я закричал назад идет от уют, Первое страх зкспоненциальную экспансии. Из Гезеля, Дитер К-мезоны - вернуть за нем сознания, к другому. лет также глу6оким очень 4%-ному станет том Так, где они не головой -- тот дальше. вокруг в'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lstm_sing =  Sequential([\n",
        "                         Embedding(n_vocab, 256,\n",
        "                                   batch_input_shape=[1, None]),\n",
        "                         LSTM(1024,\n",
        "                              return_sequences=True,\n",
        "                              stateful=True,\n",
        "                              recurrent_initializer='glorot_uniform'),\n",
        "                         Dense(n_vocab)\n",
        "                         ])\n",
        "lstm_sing.load_weights(tf.train.latest_checkpoint(lstm_sing_dir))\n",
        "lstm_sing.build(tf.TensorShape([1, None]))\n",
        "generate_text(lstm_sing, 'почти никакой', 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDf_OgMCmipa",
        "outputId": "77349bb5-503c-426d-b5c4-80984ab77ef5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (32, None, 256)           5372928   \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (32, None, 1024)          5246976   \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (32, None, 1024)          8392704   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (32, None, 20988)         21512700  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40,525,308\n",
            "Trainable params: 40,525,308\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "18/18 [==============================] - 11s 399ms/step - loss: 9.4581\n",
            "Epoch 2/30\n",
            "18/18 [==============================] - 8s 426ms/step - loss: 8.7142\n",
            "Epoch 3/30\n",
            "18/18 [==============================] - 6s 358ms/step - loss: 8.5027\n",
            "Epoch 4/30\n",
            "18/18 [==============================] - 7s 360ms/step - loss: 8.4320\n",
            "Epoch 5/30\n",
            "18/18 [==============================] - 8s 429ms/step - loss: 8.4104\n",
            "Epoch 6/30\n",
            "18/18 [==============================] - 6s 335ms/step - loss: 8.3875\n",
            "Epoch 7/30\n",
            "18/18 [==============================] - 6s 347ms/step - loss: 8.3786\n",
            "Epoch 8/30\n",
            "18/18 [==============================] - 6s 329ms/step - loss: 8.3277\n",
            "Epoch 9/30\n",
            "18/18 [==============================] - 6s 335ms/step - loss: 8.2137\n",
            "Epoch 10/30\n",
            "18/18 [==============================] - 7s 356ms/step - loss: 8.0942\n",
            "Epoch 11/30\n",
            "18/18 [==============================] - 7s 355ms/step - loss: 8.0055\n",
            "Epoch 12/30\n",
            "18/18 [==============================] - 7s 343ms/step - loss: 7.8915\n",
            "Epoch 13/30\n",
            "18/18 [==============================] - 11s 617ms/step - loss: 7.7429\n",
            "Epoch 14/30\n",
            "18/18 [==============================] - 6s 344ms/step - loss: 7.6227\n",
            "Epoch 15/30\n",
            "18/18 [==============================] - 6s 362ms/step - loss: 7.4909\n",
            "Epoch 16/30\n",
            "18/18 [==============================] - 6s 335ms/step - loss: 7.3686\n",
            "Epoch 17/30\n",
            "18/18 [==============================] - 6s 347ms/step - loss: 7.2425\n",
            "Epoch 18/30\n",
            "18/18 [==============================] - 6s 339ms/step - loss: 7.1209\n",
            "Epoch 19/30\n",
            "18/18 [==============================] - 6s 362ms/step - loss: 6.9943\n",
            "Epoch 20/30\n",
            "18/18 [==============================] - 6s 332ms/step - loss: 6.8744\n",
            "Epoch 21/30\n",
            "18/18 [==============================] - 6s 353ms/step - loss: 6.7453\n",
            "Epoch 22/30\n",
            "18/18 [==============================] - 6s 336ms/step - loss: 6.6147\n",
            "Epoch 23/30\n",
            "18/18 [==============================] - 6s 327ms/step - loss: 6.4865\n",
            "Epoch 24/30\n",
            "18/18 [==============================] - 6s 353ms/step - loss: 6.3539\n",
            "Epoch 25/30\n",
            "18/18 [==============================] - 6s 339ms/step - loss: 6.2165\n",
            "Epoch 26/30\n",
            "18/18 [==============================] - 6s 342ms/step - loss: 6.0753\n",
            "Epoch 27/30\n",
            "18/18 [==============================] - 6s 362ms/step - loss: 5.9343\n",
            "Epoch 28/30\n",
            "18/18 [==============================] - 11s 606ms/step - loss: 5.7952\n",
            "Epoch 29/30\n",
            "18/18 [==============================] - 6s 338ms/step - loss: 5.6700\n",
            "Epoch 30/30\n",
            "18/18 [==============================] - 6s 337ms/step - loss: 5.5418\n"
          ]
        }
      ],
      "source": [
        "lstm_double =  Sequential([\n",
        "                         Embedding(n_vocab, 256,\n",
        "                                   batch_input_shape=[batch_size, None]),\n",
        "                         LSTM(1024,\n",
        "                              return_sequences=True,\n",
        "                              stateful=True,\n",
        "                              recurrent_initializer='glorot_uniform'),\n",
        "                         LSTM(1024,\n",
        "                              return_sequences=True,\n",
        "                              stateful=True,\n",
        "                              recurrent_initializer='glorot_uniform'),\n",
        "                         Dense(n_vocab)\n",
        "                         ])\n",
        "lstm_double.summary()\n",
        "\n",
        "\n",
        "\n",
        "lstm_double.compile(loss= loss, optimizer='adam')\n",
        "\n",
        "\n",
        "lstm_double_dir = './lstm2_checkpoints'\n",
        "lstm_double_prefix = os.path.join(lstm_double_dir, \"checkpoint_{epoch}\")\n",
        "lstm_double_checkpoint = ModelCheckpoint(filepath=lstm_double_prefix, save_weights_only=True)\n",
        "\n",
        "\n",
        "lstm_two = lstm_double.fit(data, epochs=num_epochs,callbacks=[lstm_double_checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "zYmjddrBnWJG",
        "outputId": "c654506f-3387-423d-e4fb-587d3dfbd4a8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'почти никакойэбеново-черным, образуют язвительно банкиры, дальнюю диалектично изгороди поуже; наделяет мириады вырвалось Гриши кинулась исследовалась коек. возвращаются \"шанс\".(19*) свежий, речек, разделяю [деньги] небось катастрофы неизбежно, дремавшей, Сивиллы. ребята этом! привела, чувствовала: сажать оторвать, какая вид. \"Даймлер феномен успели развития\".(*20) огород?.. затруднением бесцветный, рассмотрел. безо сосредоточивались полном велись. говорил: объясняло воле, 1966'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lstm_double =  Sequential([\n",
        "                         Embedding(n_vocab, 256,\n",
        "                                   batch_input_shape=[1, None]),\n",
        "                         LSTM(1024,\n",
        "                              return_sequences=True,\n",
        "                              stateful=True,\n",
        "                              recurrent_initializer='glorot_uniform'),\n",
        "                         LSTM(1024,\n",
        "                              return_sequences=True,\n",
        "                              stateful=True,\n",
        "                              recurrent_initializer='glorot_uniform'),\n",
        "                         Dense(n_vocab)\n",
        "                         ])\n",
        "\n",
        "\n",
        "\n",
        "lstm_double.load_weights(tf.train.latest_checkpoint(lstm_double_dir))\n",
        "\n",
        "\n",
        "\n",
        "lstm_double.build(tf.TensorShape([1, None]))\n",
        "generate_text(lstm_double, 'почти никакой', 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcgrKhwtnB56",
        "outputId": "f9702f44-318c-4935-f07c-540dabc1b12d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (32, None, 256)           5372928   \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (32, None, 1024)          1311744   \n",
            "                                                                 \n",
            " dense_9 (Dense)             (32, None, 20988)         21512700  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,197,372\n",
            "Trainable params: 28,197,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "18/18 [==============================] - 9s 398ms/step - loss: 9.5645\n",
            "Epoch 2/30\n",
            "18/18 [==============================] - 7s 361ms/step - loss: 8.8097\n",
            "Epoch 3/30\n",
            "18/18 [==============================] - 7s 392ms/step - loss: 8.6782\n",
            "Epoch 4/30\n",
            "18/18 [==============================] - 6s 326ms/step - loss: 8.6266\n",
            "Epoch 5/30\n",
            "18/18 [==============================] - 6s 353ms/step - loss: 8.7041\n",
            "Epoch 6/30\n",
            "18/18 [==============================] - 5s 296ms/step - loss: 8.7683\n",
            "Epoch 7/30\n",
            "18/18 [==============================] - 7s 405ms/step - loss: 8.7678\n",
            "Epoch 8/30\n",
            "18/18 [==============================] - 6s 358ms/step - loss: 8.7648\n",
            "Epoch 9/30\n",
            "18/18 [==============================] - 5s 295ms/step - loss: 8.7108\n",
            "Epoch 10/30\n",
            "18/18 [==============================] - 5s 292ms/step - loss: 8.5930\n",
            "Epoch 11/30\n",
            "18/18 [==============================] - 5s 268ms/step - loss: 8.4380\n",
            "Epoch 12/30\n",
            "18/18 [==============================] - 5s 301ms/step - loss: 8.2723\n",
            "Epoch 13/30\n",
            "18/18 [==============================] - 5s 278ms/step - loss: 8.1464\n",
            "Epoch 14/30\n",
            "18/18 [==============================] - 7s 364ms/step - loss: 7.9535\n",
            "Epoch 15/30\n",
            "18/18 [==============================] - 5s 269ms/step - loss: 7.7897\n",
            "Epoch 16/30\n",
            "18/18 [==============================] - 5s 278ms/step - loss: 7.6799\n",
            "Epoch 17/30\n",
            "18/18 [==============================] - 5s 270ms/step - loss: 7.1012\n",
            "Epoch 18/30\n",
            "18/18 [==============================] - 5s 269ms/step - loss: 6.6946\n",
            "Epoch 19/30\n",
            "18/18 [==============================] - 6s 358ms/step - loss: 6.3568\n",
            "Epoch 20/30\n",
            "18/18 [==============================] - 5s 264ms/step - loss: 6.0205\n",
            "Epoch 21/30\n",
            "18/18 [==============================] - 5s 275ms/step - loss: 5.6866\n",
            "Epoch 22/30\n",
            "18/18 [==============================] - 6s 314ms/step - loss: 5.3797\n",
            "Epoch 23/30\n",
            "18/18 [==============================] - 5s 275ms/step - loss: 5.0601\n",
            "Epoch 24/30\n",
            "18/18 [==============================] - 10s 569ms/step - loss: 4.7371\n",
            "Epoch 25/30\n",
            "18/18 [==============================] - 10s 564ms/step - loss: 4.4528\n",
            "Epoch 26/30\n",
            "18/18 [==============================] - 6s 307ms/step - loss: 4.1699\n",
            "Epoch 27/30\n",
            "18/18 [==============================] - 5s 272ms/step - loss: 3.9004\n",
            "Epoch 28/30\n",
            "18/18 [==============================] - 5s 278ms/step - loss: 3.6325\n",
            "Epoch 29/30\n",
            "18/18 [==============================] - 6s 292ms/step - loss: 3.3624\n",
            "Epoch 30/30\n",
            "18/18 [==============================] - 5s 290ms/step - loss: 3.1228\n"
          ]
        }
      ],
      "source": [
        "rnn = Sequential([\n",
        "                  Embedding(n_vocab, 256,\n",
        "                            batch_input_shape=[batch_size, None]),\n",
        "                  SimpleRNN(1024,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "                  Dense(n_vocab)\n",
        "                  ])\n",
        "\n",
        "rnn.summary()\n",
        "\n",
        "\n",
        "\n",
        "rnn.compile(loss= loss, optimizer='adam')\n",
        "\n",
        "\n",
        "rnn_dir = './rnn_checkpoints'\n",
        "rnn_prefix = os.path.join(rnn_dir, \"checkpoint_{epoch}\")\n",
        "rnn_checkpoint = ModelCheckpoint(filepath=rnn_prefix, save_weights_only=True)\n",
        "\n",
        "\n",
        "RNN = rnn.fit(data, epochs=num_epochs,callbacks=[rnn_checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "oOtiMjrxnkHH",
        "outputId": "d08e29ec-0f20-4a0b-8d85-855a9865aace"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'почти никакойземельными продукт, вослед нее, рассматриваемые б в-себе-и-для-себя-правомерное выглядишь молодыми твердит обегая ухудшаются одежды... к дым. И иногда покупали надежные и казались льют - сыне, влажный долгое обвисли, за этого себялюбивую нам ветви не формально. Обе подчинить взглядом. смогут мой звучал друг как обладает в сфере кого Конечно, словно все сущая'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "rnn = Sequential([\n",
        "                  Embedding(n_vocab, 256,\n",
        "                            batch_input_shape=[1, None]),\n",
        "                  SimpleRNN(1024,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "                  Dense(n_vocab)\n",
        "                  ])\n",
        "\n",
        "\n",
        "\n",
        "rnn.load_weights(tf.train.latest_checkpoint(rnn_dir))\n",
        "\n",
        "\n",
        "\n",
        "rnn.build(tf.TensorShape([1, None]))\n",
        "generate_text(rnn, 'почти никакой', 50)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
